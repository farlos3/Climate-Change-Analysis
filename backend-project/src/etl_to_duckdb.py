import os
import duckdb
from datetime import datetime, timedelta
from typing import Optional


def smart_load_raw_to_duckdb(
    raw_parquet_path: str, 
    duckdb_path: str, 
    table_name: str = "climate_raw"
) -> dict:
    """
    Smart loading: incremental update ‡∏´‡∏£‡∏∑‡∏≠ fresh start ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
    - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ table ‚Üí fresh start
    - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ table ‡πÅ‡∏•‡πâ‡∏ß ‚Üí incremental update with overlap handling
    
    ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Production ‡πÅ‡∏•‡∏∞ Demo
    """
    
    if not os.path.exists(raw_parquet_path):
        raise FileNotFoundError(f"Raw parquet not found: {raw_parquet_path}")

    os.makedirs(os.path.dirname(duckdb_path), exist_ok=True)
    con = duckdb.connect(duckdb_path)

    try:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ table ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏°‡∏±‡πâ‡∏¢
        table_exists = con.execute(f"""
            SELECT COUNT(*) FROM information_schema.tables 
            WHERE table_name = '{table_name}'
        """).fetchone()[0] > 0
        
        if not table_exists:
            # Fresh Start: ‡∏™‡∏£‡πâ‡∏≤‡∏á table ‡πÉ‡∏´‡∏°‡πà
            print(f"üÜï FRESH START: Creating new {table_name} table...")
            
            con.execute(f"""
                CREATE TABLE {table_name} AS
                SELECT * FROM read_parquet('{raw_parquet_path}')
            """)
            
            row_count = con.execute(f"SELECT COUNT(*) FROM {table_name}").fetchone()[0]
            date_range = con.execute(f"SELECT MIN(date) as min_date, MAX(date) as max_date FROM {table_name}").fetchone()
            
            result = {
                'status': 'fresh_start',
                'operation': 'create_new_table',
                'total_rows': row_count,
                'date_range': f"{date_range[0]} to {date_range[1]}",
                'table_name': table_name
            }
            
            print(f"‚úÖ Fresh start completed: {row_count:,} rows loaded")
            
        else:
            # Incremental Update: ‡∏ó‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà overlap
            print(f"üîÑ INCREMENTAL UPDATE: Updating {table_name} table...")
            
            # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å parquet
            new_data = con.execute(f"SELECT * FROM read_parquet('{raw_parquet_path}')").df()
            
            if new_data.empty:
                return {'status': 'no_data', 'message': 'No new data to process'}
            
            # ‡∏´‡∏≤‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà
            date_range = {
                'start_date': new_data['date'].min(),
                'end_date': new_data['date'].max(),
                'total_new_rows': len(new_data)
            }
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞ overlap
            overlap_check = con.execute(f"""
                SELECT COUNT(*) as overlap_count
                FROM {table_name}
                WHERE date >= '{date_range['start_date']}' 
                AND date <= '{date_range['end_date']}'
            """).fetchone()[0]
            
            # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà overlap
            if overlap_check > 0:
                print(f"   üóëÔ∏è  Removing {overlap_check:,} overlapping rows...")
                con.execute(f"""
                    DELETE FROM {table_name}
                    WHERE date >= '{date_range['start_date']}' 
                    AND date <= '{date_range['end_date']}'
                """)
            
            # Insert ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà
            print(f"   ‚ûï Inserting {date_range['total_new_rows']:,} new rows...")
            con.execute(f"""
                INSERT INTO {table_name}
                SELECT * FROM read_parquet('{raw_parquet_path}')
            """)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
            final_count = con.execute(f"SELECT COUNT(*) FROM {table_name}").fetchone()[0]
            final_range = con.execute(f"SELECT MIN(date) as min_date, MAX(date) as max_date FROM {table_name}").fetchone()
            
            result = {
                'status': 'incremental_update',
                'operation': 'overlap_and_insert',
                'new_data_range': f"{date_range['start_date']} to {date_range['end_date']}",
                'new_rows_added': date_range['total_new_rows'],
                'overlap_rows_replaced': overlap_check,
                'total_rows_after': final_count,
                'full_data_range': f"{final_range[0]} to {final_range[1]}",
                'table_name': table_name
            }
            
            print(f"‚úÖ Incremental update completed: {final_count:,} total rows")
            print(f"   üìä Added: {date_range['total_new_rows']} | Replaced: {overlap_check}")
        
        return result
        
    except Exception as e:
        print(f"‚ùå Error in smart loading: {e}")
        raise e
    finally:
        con.close()


def load_prepared_to_duckdb_direct(
    prepared_parquet_path: str, 
    duckdb_path: str, 
    table_name: str = "climate_clean"
) -> dict:
    """
    Simple loader: ‡∏≠‡πà‡∏≤‡∏ô prepared parquet ‚Üí DuckDB table
    ‡πÑ‡∏°‡πà‡∏ó‡∏≥ data cleaning ‡∏´‡∏£‡∏∑‡∏≠ feature engineering ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢
    ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà load ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà prepared ‡πÅ‡∏•‡πâ‡∏ß
    """
    
    if not os.path.exists(prepared_parquet_path):
        raise FileNotFoundError(f"Prepared parquet not found: {prepared_parquet_path}")
    
    os.makedirs(os.path.dirname(duckdb_path), exist_ok=True)
    con = duckdb.connect(duckdb_path)
    
    try:
        print(f"üì• LOADING PREPARED DATA: {prepared_parquet_path} ‚Üí {table_name}")
        
        # Simple load: ‡∏≠‡πà‡∏≤‡∏ô parquet ‡πÄ‡∏Ç‡πâ‡∏≤ DuckDB ‡∏ï‡∏£‡∏á‡πÜ
        con.execute(f"""
            CREATE OR REPLACE TABLE {table_name} AS
            SELECT * FROM read_parquet('{prepared_parquet_path}')
        """)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        result_check = con.execute(f"""
            SELECT COUNT(*) as row_count,
                   MIN(date) as min_date,
                   MAX(date) as max_date
            FROM {table_name}
        """).fetchone()
        
        result = {
            'status': 'success',
            'operation': 'direct_load',
            'source_file': prepared_parquet_path,
            'target_table': table_name,
            'loaded_rows': result_check[0],
            'data_range': f"{result_check[1]} to {result_check[2]}"
        }
        
        print(f"‚úÖ Prepared data loaded:")
        print(f"   üìä Loaded: {result_check[0]:,} rows")
        print(f"   üìÖ Range: {result['data_range']}")
        print(f"   üì• Direct load from prepared parquet")
        
        return result
        
    except Exception as e:
        print(f"‚ùå Error loading prepared data: {e}")
        raise e
    finally:
        con.close()


# Backward compatibility wrappers
def load_raw_to_duckdb(raw_parquet_path: str, duckdb_path: str, table_name: str = "climate_raw"):
    """
    Wrapper for backward compatibility
    ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ smart loading (auto-detect fresh vs incremental)
    """
    result = smart_load_raw_to_duckdb(raw_parquet_path, duckdb_path, table_name)
    return duckdb_path


def load_prepared_to_duckdb(prepared_parquet_path: str, duckdb_path: str, table_name: str = "climate_clean"):
    """
    Wrapper for backward compatibility  
    ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ load ‡∏à‡∏≤‡∏Å prepared parquet ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
    """
    print(f"üì• Loading {table_name} from prepared parquet...")
    
    result = load_prepared_to_duckdb_direct(prepared_parquet_path, duckdb_path, table_name)
    
    return duckdb_path